{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d505c82",
   "metadata": {},
   "source": [
    "# **Código Base de datos por Localidad (Indicadores integrados, VIV + DENUE)**\n",
    "Esto será el código para crear la base de datos por localidad. <br>\n",
    "<br>\n",
    "No toma ninguna otra BD como base, lo crea desde cero, con los datos censales por localidad.\n",
    "<br>\n",
    "Agrupa, además, los resultados por municipio y por zona metropolitana, generando bases de datos adicionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e76c9ce-0451-45d7-8697-33c4f4fee3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jenkspy\n",
      "  Downloading jenkspy-0.4.1-cp312-cp312-win_amd64.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\amim gtac\\anaconda3\\lib\\site-packages (from jenkspy) (1.26.4)\n",
      "Downloading jenkspy-0.4.1-cp312-cp312-win_amd64.whl (224 kB)\n",
      "Installing collected packages: jenkspy\n",
      "Successfully installed jenkspy-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jenkspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819e440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Polygon\n",
    "from dbfread import DBF\n",
    "import jenkspy\n",
    "import json\n",
    "from jenkspy import jenks_breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e1cf5",
   "metadata": {},
   "source": [
    "## Paso dos - Información censal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9ded02b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #RUTAS ENTRADA - ALEJANDRO (Local)\n",
    "# ITER_2020_ruta = r\"C:\\Users\\Alejandro\\Downloads\\DATA\\2020\\ITER\\ITER_NALCSV20.csv\"\n",
    "# ITER_2010_ruta = r\"C:\\Users\\Alejandro\\Downloads\\DATA\\2010\\ITER\\ITER_NALDBF10.dbf\"\n",
    "\n",
    "# # ruta shp base\n",
    "# SHP_LOC_NAC_ruta = r\"C:\\Users\\Alejandro\\Downloads\\DATA\\SHP\\mg_2020_integrado\\conjunto_de_datos\\00l.shp\"\n",
    "\n",
    "# #ruta gpkg fin\n",
    "# MAPA_TIPO_ruta = r\"C:\\Users\\Alejandro\\Downloads\\DATA\\Tratados\\NAC\\DENUE_LOC_NAC\\Loc_Tipologías_NAC.gpkg\"\n",
    "\n",
    "#RUTAS ENTRADA - ALEJANDRO (SSD)\n",
    "ITER_2020_ruta = r\"Z:\\VOCES\\DATA\\2020\\ITER\\ITER_NALCSV20.csv\"\n",
    "ITER_2010_ruta = r\"Z:\\VOCES\\DATA\\2010\\ITER\\ITER_NALDBF10.dbf\"\n",
    "\n",
    "# ruta shp base\n",
    "SHP_LOC_NAC_ruta = r\"Z:\\VOCES\\DATA\\SHP\\mg_2020_integrado\\conjunto_de_datos\\00l.shp\"\n",
    "SHP_LOC_NAC_2010_ruta = r\"Z:\\VOCES\\DATA\\SHP\\mglu2010v5_0\\poligonos_urbanos.shp\"\n",
    "\n",
    "#ruta gpkg fin\n",
    "MAPA_TIPO_ruta = r\"Z:\\VOCES\\DATA\\Tratados\\NAC\\INT_LOC_NAC\\Loc_Tipologías_NAC.gpkg\"\n",
    "\n",
    "# Ruta del archivo shp de polígonos\n",
    "polygons_path = r\"Z:\\VOCES\\DATA\\PCU_2018_SHP\\PCUS_2018.shp\"\n",
    "\n",
    "#rutas claves metro\n",
    "CVE_METRO_ruta = r\"Z:\\VOCES\\DATA\\Claves_Metro.csv\"\n",
    "\n",
    "#rutas denue\n",
    "ruta_denue = r\"Z:\\VOCES\\DATA\\Tratados\\NAC\\DENUE.gpkg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1be14661-20e8-4de5-8665-ab0c132e0b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alejandro\\AppData\\Local\\Temp\\ipykernel_22552\\2056174885.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ITER_2020_df = pd.read_csv(ITER_2020_ruta, dtype={'ENTIDAD': str, 'MUN': str, 'LOC': str, 'AGEB': str, 'MZA': str})\n"
     ]
    }
   ],
   "source": [
    "# PASO DOS - Preparación de información censal\n",
    "\n",
    "# Función para cargar datos de archivo DBF y convertirlos a DataFrame\n",
    "def load_dbf_to_dataframe(file_path):\n",
    "    table = DBF(file_path)\n",
    "    return pd.DataFrame(iter(table))\n",
    "\n",
    "# Cargar archivos en un DataFrame\n",
    "ITER_2020_df = pd.read_csv(ITER_2020_ruta, dtype={'ENTIDAD': str, 'MUN': str, 'LOC': str, 'AGEB': str, 'MZA': str})\n",
    "ITER_2010_df = load_dbf_to_dataframe(ITER_2010_ruta)\n",
    "\n",
    "# Homologación de ID rural - CVEGEO\n",
    "def homologate_rural_id(row):\n",
    "    return f\"{row['ENTIDAD']}{row['MUN']}{row['LOC']}\"\n",
    "\n",
    "ITER_2020_df['CVEGEO'] = ITER_2020_df.apply(homologate_rural_id, axis=1)\n",
    "ITER_2010_df['CVEGEO'] = ITER_2010_df.apply(homologate_rural_id, axis=1)\n",
    "\n",
    "# reemplazar * con 1\n",
    "def replace(dataframe):\n",
    "    return dataframe.replace('*', '1')\n",
    "\n",
    "ITER_2020_df = replace(ITER_2020_df)\n",
    "ITER_2010_df = replace(ITER_2010_df)\n",
    "\n",
    "\n",
    "# Leer el archivo de polígonos\n",
    "polygons_gdf = gpd.read_file(polygons_path)[['geometry', 'CALIF_CLAS']]\n",
    "\n",
    "# Define el CRS proyectado que deseas utilizar\n",
    "CRS_PROYECTADO = 'EPSG:6372' \n",
    "\n",
    "# Leer shp base y convertir a gpkg\n",
    "SHP_LOC_gdf = gpd.read_file(SHP_LOC_NAC_ruta)\n",
    "\n",
    "# Proyecta el GeoDataFrame a un CRS proyectado\n",
    "SHP_LOC_gdf = SHP_LOC_gdf.to_crs(CRS_PROYECTADO)\n",
    "polygons_gdf = polygons_gdf.to_crs(CRS_PROYECTADO)\n",
    "\n",
    "# CREAR GPKG BASE DESDE gdf DE MANZANAS\n",
    "SHP_LOC_gdf.to_file(MAPA_TIPO_ruta, layer='Mapa_Tipologias', driver='GPKG')\n",
    "\n",
    "# Leer gpkg base\n",
    "MAPA_TIPO_gdf = gpd.read_file(MAPA_TIPO_ruta, layer='Mapa_Tipologias')\n",
    "\n",
    "# Filtrar entidades rurales que intersectan con los polígonos\n",
    "MAPA_TIPO_gdf_INTERSECT = gpd.sjoin(MAPA_TIPO_gdf, polygons_gdf, how='left', predicate='intersects')\n",
    "\n",
    "# Eliminar duplicados basados en el identificador de SHP_LOC_gdf\n",
    "MAPA_TIPO_gdf_INTERSECT = MAPA_TIPO_gdf_INTERSECT.drop_duplicates(subset=SHP_LOC_gdf.columns.tolist())\n",
    "\n",
    "# Guardar la capa concatenada en el GeoPackage base\n",
    "MAPA_TIPO_gdf_INTERSECT.to_file(MAPA_TIPO_ruta, layer='Mapa_Tipologias', driver='GPKG', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa1cfc35-de4f-4730-bf71-138ee5ff3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratar shape 2010\n",
    "\n",
    "# Leer shp 2010 y convertir a gpkg\n",
    "SHP_2010_gdf = gpd.read_file(SHP_LOC_NAC_2010_ruta)\n",
    "\n",
    "# Proyecta el GeoDataFrame a un CRS proyectado\n",
    "SHP_2010_gdf = SHP_2010_gdf.to_crs(CRS_PROYECTADO)\n",
    "\n",
    "# Homologación de ID rural - CVEGEO\n",
    "def homologate_2010_id(row):\n",
    "    return f\"{row['CVE_ENT']}{row['CVE_MUN']}{row['CVE_LOC']}\"\n",
    "\n",
    "SHP_2010_gdf['CVEGEO'] = SHP_2010_gdf.apply(homologate_2010_id, axis=1)\n",
    "\n",
    "SHP_2010_gdf['area_2010'] = SHP_2010_gdf.area / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37821431-bfab-4632-a211-524330fd096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer gpkg base\n",
    "MAPA_TIPO_gdf = gpd.read_file(MAPA_TIPO_ruta, layer='Mapa_Tipologias')\n",
    "\n",
    "# Filtrar censos\n",
    "ITER_2020_df_F = ITER_2020_df[['CVEGEO', 'POBTOT', 'VIVTOT', 'TVIVHAB', 'TVIVPAR', 'TVIVPARHAB', 'VIVPAR_HAB', 'VIVPAR_UT', 'OCUPVIVPAR', 'VIVPAR_DES', 'VPH_1CUART', 'VPH_2CUART', 'VPH_3YMASC']]\n",
    "ITER_2010_df_F = ITER_2010_df[['CVEGEO', 'POBTOT', 'VIVTOT', 'TVIVHAB', 'TVIVPAR', 'TVIVPARHAB', 'VIVPAR_HAB', 'VIVPAR_UT', 'OCUPVIVPAR', 'VIVPAR_DES', 'VPH_1CUART', 'VPH_2CUART', 'VPH_3YMASC']]\n",
    "\n",
    "# Renombrar columnas de ITER_2020_df antes del merge para evitar conflictos\n",
    "ITER_2020_df_renamed = ITER_2020_df_F.rename(columns={\n",
    "    'POBTOT': 'POPTOT2020',\n",
    "    'VIVTOT': 'VIVTOT2020',\n",
    "    'TVIVHAB': 'TVIVHAB2020',\n",
    "    'TVIVPAR': 'TVIVPAR2020',\n",
    "    'TVIVPARHAB': 'TVIVPARHAB2020',\n",
    "    'VIVPAR_HAB': 'VIVPAR_HAB2020',\n",
    "    'VIVPAR_UT': 'VIVPAR_UT2020',\n",
    "    'OCUPVIVPAR': 'OCUPVIVPAR2020',\n",
    "    'VIVPAR_DES': 'VIVPAR_DES2020',\n",
    "    'VPH_1CUART': 'VIV1C2020',\n",
    "    'VPH_2CUART': 'VIV2C2020',\n",
    "    'VPH_3YMASC': 'VIV3C2020'\n",
    "})\n",
    "\n",
    "ITER_2010_df_renamed = ITER_2010_df_F.rename(columns={\n",
    "    'POBTOT': 'POPTOT2010',\n",
    "    'VIVTOT': 'VIVTOT2010',\n",
    "    'TVIVHAB': 'TVIVHAB2010',\n",
    "    'TVIVPAR': 'TVIVPAR2010',\n",
    "    'TVIVPARHAB': 'TVIVPARHAB2010',\n",
    "    'VIVPAR_HAB': 'VIVPAR_HAB2010',\n",
    "    'VIVPAR_UT': 'VIVPAR_UT2010',\n",
    "    'OCUPVIVPAR': 'OCUPVIVPAR2010',\n",
    "    'VIVPAR_DES': 'VIVPAR_DES2010',\n",
    "    'VPH_1CUART': 'VIV1C2010',\n",
    "    'VPH_2CUART': 'VIV2C2010',\n",
    "    'VPH_3YMASC': 'VIV3C2010'\n",
    "})\n",
    "\n",
    "MAPA_TIPO_gdf['CVEGEO'] = MAPA_TIPO_gdf['CVEGEO'].astype(str)\n",
    "ITER_2020_df_renamed['CVEGEO'] = ITER_2020_df_renamed['CVEGEO'].astype(str)\n",
    "ITER_2010_df_renamed['CVEGEO'] = ITER_2010_df_renamed['CVEGEO'].astype(str)\n",
    "\n",
    "# Unir campos de los DataFrames al GeoPackage base por CVEGEO\n",
    "MAPA_TIPO_gdf1 = MAPA_TIPO_gdf.merge(\n",
    "    ITER_2020_df_renamed[['CVEGEO', 'POPTOT2020', 'VIVTOT2020', 'TVIVHAB2020', 'TVIVPAR2020', 'TVIVPARHAB2020', 'VIVPAR_HAB2020', 'VIVPAR_UT2020', 'OCUPVIVPAR2020', 'VIVPAR_DES2020', 'VIV1C2020', 'VIV2C2020', 'VIV3C2020']],\n",
    "    on='CVEGEO', how='left')\n",
    "\n",
    "MAPA_TIPO_gdf2 = MAPA_TIPO_gdf1.merge(\n",
    "    ITER_2010_df_renamed[['CVEGEO', 'POPTOT2010', 'VIVTOT2010', 'TVIVHAB2010', 'TVIVPAR2010', 'TVIVPARHAB2010', 'VIVPAR_HAB2010', 'VIVPAR_UT2010', 'OCUPVIVPAR2010', 'VIVPAR_DES2010', 'VIV1C2010', 'VIV2C2010', 'VIV3C2010']],\n",
    "    on='CVEGEO', how='left')\n",
    "\n",
    "MAPA_TIPO_gdf2 = MAPA_TIPO_gdf2.merge(\n",
    "    SHP_2010_gdf[['CVEGEO', 'area_2010']],\n",
    "    on='CVEGEO', how='left')\n",
    "\n",
    "# Reemplazar * con 1\n",
    "def replace(dataframe):\n",
    "    return dataframe.replace('*', '1')\n",
    "\n",
    "# Limpiar *\n",
    "MAPA_TIPO_gdf2_A = replace(MAPA_TIPO_gdf2)\n",
    "\n",
    "# Reemplazar N/D\n",
    "MAPA_TIPO_gdf2_B = MAPA_TIPO_gdf2_A.replace('N/D', np.nan)\n",
    "\n",
    "# Actualizar valores sin información de \"null\" a 0\n",
    "MAPA_TIPO_gdf2_C = MAPA_TIPO_gdf2_B.fillna(0)\n",
    "\n",
    "# Convertir campos a enteros\n",
    "fields_to_convert = ['POPTOT2010', 'POPTOT2020', 'VIVTOT2010', 'VIVTOT2020', \n",
    "    'TVIVHAB2010', 'TVIVHAB2020', 'TVIVPAR2010', 'TVIVPAR2020',\n",
    "    'TVIVPARHAB2010', 'TVIVPARHAB2020', 'VIVPAR_HAB2010', 'VIVPAR_HAB2020',\n",
    "    'VIVPAR_UT2010', 'VIVPAR_UT2020', 'OCUPVIVPAR2010', 'OCUPVIVPAR2020',\n",
    "    'VIVPAR_DES2010', 'VIVPAR_DES2020', 'VIV1C2010', 'VIV1C2020', \n",
    "    'VIV2C2010', 'VIV2C2020', 'VIV3C2010', 'VIV3C2020']\n",
    "for field in fields_to_convert:\n",
    "    MAPA_TIPO_gdf2_C[field] = MAPA_TIPO_gdf2_C[field].astype(int)\n",
    "\n",
    "# Reordenar columnas\n",
    "ordered_columns = [\n",
    "    'CVEGEO', 'POPTOT2010', 'POPTOT2020', 'VIVTOT2010', 'VIVTOT2020', \n",
    "    'TVIVHAB2010', 'TVIVHAB2020', 'TVIVPAR2010', 'TVIVPAR2020',\n",
    "    'TVIVPARHAB2010', 'TVIVPARHAB2020', 'VIVPAR_HAB2010', 'VIVPAR_HAB2020',\n",
    "    'VIVPAR_UT2010', 'VIVPAR_UT2020', 'OCUPVIVPAR2010', 'OCUPVIVPAR2020',\n",
    "    'VIVPAR_DES2010', 'VIVPAR_DES2020', 'VIV1C2010', 'VIV1C2020', \n",
    "    'VIV2C2010', 'VIV2C2020', 'VIV3C2010', 'VIV3C2020','area_2010'\n",
    "] + [col for col in MAPA_TIPO_gdf2.columns if col not in [\n",
    "    'CVEGEO', 'POPTOT2010', 'POPTOT2020', 'VIVTOT2010', 'VIVTOT2020', \n",
    "    'TVIVHAB2010', 'TVIVHAB2020', 'TVIVPAR2010', 'TVIVPAR2020',\n",
    "    'TVIVPARHAB2010', 'TVIVPARHAB2020', 'VIVPAR_HAB2010', 'VIVPAR_HAB2020',\n",
    "    'VIVPAR_UT2010', 'VIVPAR_UT2020', 'OCUPVIVPAR2010', 'OCUPVIVPAR2020',\n",
    "    'VIVPAR_DES2010', 'VIVPAR_DES2020', 'VIV1C2010', 'VIV1C2020', \n",
    "    'VIV2C2010', 'VIV2C2020', 'VIV3C2010', 'VIV3C2020','area_2010'\n",
    "]]\n",
    "\n",
    "\n",
    "MAPA_TIPO_gdf2_C = MAPA_TIPO_gdf2_C[ordered_columns]\n",
    "\n",
    "# Guardar el GeoPackage base actualizado\n",
    "MAPA_TIPO_gdf2_C.to_file(MAPA_TIPO_ruta, layer='BASE_DATOS_NAC_LOC', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dba5c55d-9c91-453d-99e4-2f7aedaff7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CVEGEO', 'POPTOT2010', 'POPTOT2020', 'VIVTOT2010', 'VIVTOT2020',\n",
       "       'TVIVHAB2010', 'TVIVHAB2020', 'TVIVPAR2010', 'TVIVPAR2020',\n",
       "       'TVIVPARHAB2010', 'TVIVPARHAB2020', 'VIVPAR_HAB2010', 'VIVPAR_HAB2020',\n",
       "       'VIVPAR_UT2010', 'VIVPAR_UT2020', 'OCUPVIVPAR2010', 'OCUPVIVPAR2020',\n",
       "       'VIVPAR_DES2010', 'VIVPAR_DES2020', 'VIV1C2010', 'VIV1C2020',\n",
       "       'VIV2C2010', 'VIV2C2020', 'VIV3C2010', 'VIV3C2020', 'area_2010',\n",
       "       'CVE_ENT', 'CVE_MUN', 'CVE_LOC', 'NOMGEO', 'AMBITO', 'index_right',\n",
       "       'CALIF_CLAS', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAPA_TIPO_gdf2_C.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7015999-1a6c-4f58-a49f-b9c0dc9704a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGRUPAR Y ASIGNAR FILTRO Y PROM POR ZM\n",
    "\n",
    "#Subir archivo con CVE_METRO\n",
    "CVE_METRO_df = pd.read_csv(CVE_METRO_ruta, dtype={'CVE_MET': str, 'CVEMUN':str})\n",
    "\n",
    "# Leer la capa existente del GeoPackage base\n",
    "MAPA_TIPO_gdf = gpd.read_file(MAPA_TIPO_ruta, layer='BASE_DATOS_NAC_LOC')\n",
    "\n",
    "#Crear campo CVEMUN\n",
    "def homologate_municipio_id(row):\n",
    "    return f\"{row['CVE_ENT']}{row['CVE_MUN']}\"\n",
    "\n",
    "MAPA_TIPO_gdf['CVEMUN'] = MAPA_TIPO_gdf.apply(homologate_municipio_id, axis=1)\n",
    "\n",
    "#Añadir claves a GPKG\n",
    "MAPA_TIPO_gdf = MAPA_TIPO_gdf.merge(CVE_METRO_df[['CVEMUN', 'CVE_MET', 'NOM_MET', 'TIPO_MET','TIPO_MUN']], on='CVEMUN', how='left')\n",
    "\n",
    "#FILTRAR MUNICIPIOS ZONAS METROPOLITANAS\n",
    "valores_filtro = CVE_METRO_df['CVEMUN'].unique()\n",
    "\n",
    "MAPA_TIPO_gdf = MAPA_TIPO_gdf[(MAPA_TIPO_gdf['CVEMUN'].isin(valores_filtro))]\n",
    "\n",
    "# Guardar el GeoPackage base actualizado\n",
    "MAPA_TIPO_gdf.to_file(MAPA_TIPO_ruta, layer= 'BASE_DATOS_METRO_LOC', driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e03becaf-7d1b-4e8c-836a-9bc699eb8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer la capa existente del GeoPackage base\n",
    "MAPA_TIPO_gdf = gpd.read_file(MAPA_TIPO_ruta, layer='BASE_DATOS_METRO_LOC')\n",
    "\n",
    "# Creación de campos y llenado de información\n",
    "\n",
    "MAPA_TIPO_gdf['area_ha'] = MAPA_TIPO_gdf.area / 10000\n",
    "MAPA_TIPO_gdf['DESHABITACION'] = MAPA_TIPO_gdf['VIVPAR_DES2020'] / MAPA_TIPO_gdf['VIVTOT2020']\n",
    "MAPA_TIPO_gdf['DIFPOP'] = MAPA_TIPO_gdf['POPTOT2020'] - MAPA_TIPO_gdf['POPTOT2010']\n",
    "MAPA_TIPO_gdf['DIFVIV'] = MAPA_TIPO_gdf['VIVTOT2020'] - MAPA_TIPO_gdf['VIVTOT2010']\n",
    "MAPA_TIPO_gdf['RELPOP'] = MAPA_TIPO_gdf['DIFPOP'] / MAPA_TIPO_gdf['POPTOT2010']\n",
    "MAPA_TIPO_gdf['RELVIV'] = MAPA_TIPO_gdf['DIFVIV'] / MAPA_TIPO_gdf['VIVTOT2010']\n",
    "MAPA_TIPO_gdf['CVEPOP'] = np.where(MAPA_TIPO_gdf['RELPOP'] < -0.000000001, 'A', 'B')\n",
    "MAPA_TIPO_gdf['CVEVIV'] = np.where(MAPA_TIPO_gdf['RELVIV'] < -.0703, '1',\n",
    "                                   np.where((MAPA_TIPO_gdf['RELVIV'] >= -.0703) & (MAPA_TIPO_gdf['RELVIV'] <= .0703), \n",
    "                                            '2', '3'))\n",
    "MAPA_TIPO_gdf['CVE'] = MAPA_TIPO_gdf['CVEPOP'] + MAPA_TIPO_gdf['CVEVIV'].astype(str)\n",
    "conditions = [\n",
    "    (MAPA_TIPO_gdf['POPTOT2020'] == 0),\n",
    "    (MAPA_TIPO_gdf['POPTOT2010'] == 0) & (MAPA_TIPO_gdf['VIVTOT2010'] == 0) & (MAPA_TIPO_gdf['CVE'] == 'B3')\n",
    "]\n",
    "choices = ['DH', 'B3\\'']\n",
    "MAPA_TIPO_gdf['TIPOLOGIA'] = np.select(conditions, choices, default=MAPA_TIPO_gdf['CVE'])\n",
    "\n",
    "MAPA_TIPO_gdf['DENS_POP10'] = MAPA_TIPO_gdf['POPTOT2010'] / MAPA_TIPO_gdf['area_2010']\n",
    "MAPA_TIPO_gdf['DENS_POP20'] = MAPA_TIPO_gdf['POPTOT2020'] / MAPA_TIPO_gdf['area_ha']\n",
    "\n",
    "MAPA_TIPO_gdf['DENS_VIV10'] = MAPA_TIPO_gdf['VIVTOT2010'] / MAPA_TIPO_gdf['area_2010']\n",
    "MAPA_TIPO_gdf['DENS_VIV20'] = MAPA_TIPO_gdf['VIVTOT2020'] / MAPA_TIPO_gdf['area_ha']\n",
    "\n",
    "MAPA_TIPO_gdf['CUARTOS2010'] = ((MAPA_TIPO_gdf['VIV1C2010']*1) + (MAPA_TIPO_gdf['VIV2C2010']*2) + (MAPA_TIPO_gdf['VIV3C2010']*4))\n",
    "MAPA_TIPO_gdf['CUARTOS2020'] = ((MAPA_TIPO_gdf['VIV1C2020']*1) + (MAPA_TIPO_gdf['VIV2C2020']*2) + (MAPA_TIPO_gdf['VIV3C2020']*4))\n",
    "\n",
    "MAPA_TIPO_gdf['CPERC2010'] = MAPA_TIPO_gdf['CUARTOS2010'] / MAPA_TIPO_gdf['POPTOT2010']\n",
    "MAPA_TIPO_gdf['CPERC2020'] = MAPA_TIPO_gdf['CUARTOS2020'] / MAPA_TIPO_gdf['POPTOT2020']\n",
    "\n",
    "MAPA_TIPO_gdf['HABXVIV2010'] = MAPA_TIPO_gdf['POPTOT2010'] / MAPA_TIPO_gdf['VIVTOT2010']\n",
    "MAPA_TIPO_gdf['HABXVIV2020'] = MAPA_TIPO_gdf['POPTOT2020'] / MAPA_TIPO_gdf['VIVTOT2020']\n",
    "\n",
    "def asignar_subtipologia(row):\n",
    "    # Valores específicos para deshabitación\n",
    "    rangos_deshabitacion_grupo = [0, .0703, .1416, .2812]  # Modifica estos valores según tus necesidades\n",
    "    \n",
    "# Asignar subtipología según los rangos definidos\n",
    "    if rangos_deshabitacion_grupo[0] <= row['DESHABITACION'] < rangos_deshabitacion_grupo[1]:\n",
    "        return 'a'\n",
    "    elif rangos_deshabitacion_grupo[1] <= row['DESHABITACION'] < rangos_deshabitacion_grupo[2]:\n",
    "        return 'b'\n",
    "    elif rangos_deshabitacion_grupo[2] <= row['DESHABITACION'] < rangos_deshabitacion_grupo[3]:\n",
    "        return 'c'\n",
    "    elif row['DESHABITACION'] >= rangos_deshabitacion_grupo[3]:\n",
    "        return 'd'\n",
    "    else:\n",
    "        return '0'  # Valor predeterminado\n",
    "\n",
    "# Crear un nuevo campo 'R_DESHAB' y llenarlo con las subtipologías asignadas\n",
    "MAPA_TIPO_gdf['R_DESHAB'] = MAPA_TIPO_gdf.apply(asignar_subtipologia, axis=1)\n",
    "\n",
    "# Crear el campo SUBTIPOLOGÍA\n",
    "MAPA_TIPO_gdf['SUBTIPOLOGÍA'] = MAPA_TIPO_gdf['TIPOLOGIA'].astype(str) + '-' + MAPA_TIPO_gdf['R_DESHAB'].astype(str)\n",
    "\n",
    "# Guardar el GeoPackage con los nuevos campos\n",
    "MAPA_TIPO_gdf.to_file(MAPA_TIPO_ruta, layer='Loc_Subtipologias', driver='GPKG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57a79a-b304-4e79-bdcc-e0edda19e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "## datos DENUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74c77555-223c-4977-b9f3-fe790ba5d2b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cargar los GeoDataFrames de las manzanas y las unidades económicas\n",
    "MAPA_TIPO_gdf = gpd.read_file(MAPA_TIPO_ruta, layer='Loc_Subtipologias')\n",
    "\n",
    "SHP_DENUE_2020_gdf = gpd.read_file(ruta_denue, layer='2020')\n",
    "SHP_DENUE_2010_gdf = gpd.read_file(ruta_denue, layer='2010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "930b929e-399a-4f2d-bb3a-5f2d552e2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que ambos datasets tienen el mismo sistema de coordenadas\n",
    "if MAPA_TIPO_gdf.crs != SHP_DENUE_2020_gdf.crs:\n",
    "    SHP_DENUE_2020_gdf = SHP_DENUE_2020_gdf.to_crs(MAPA_TIPO_gdf.crs)\n",
    "if MAPA_TIPO_gdf.crs != SHP_DENUE_2010_gdf.crs:\n",
    "    SHP_DENUE_2010_gdf = SHP_DENUE_2010_gdf.to_crs(MAPA_TIPO_gdf.crs)\n",
    "\n",
    "# Función para contar las unidades económicas y sumar empleados dentro de los polígonos\n",
    "def calcular_datos(localidades, ue_data, col_ue, col_emp):\n",
    "    # Realizar un 'spatial join' para unir los puntos con los polígonos en los que caen\n",
    "    join = gpd.sjoin(ue_data, localidades, how=\"inner\", predicate='within', rsuffix='_localidad')\n",
    "\n",
    "    # Calcular el conteo de unidades económicas y la suma de empleados por polígono\n",
    "    conteo_ue = join.groupby('CVEGEO').size()  # Cuenta las unidades económicas por CVEGEO\n",
    "    suma_emp = join.groupby('CVEGEO')['num_emp'].sum()  # Suma los empleados por CVEGEO\n",
    "\n",
    "    # Asignar los resultados al geodataframe de localidades usando CVEGEO como clave única\n",
    "    localidades[col_ue] = localidades['CVEGEO'].map(conteo_ue).fillna(0).astype(int)\n",
    "    localidades[col_emp] = localidades['CVEGEO'].map(suma_emp).fillna(0).astype(int)\n",
    "\n",
    "# Calcular datos\n",
    "calcular_datos(MAPA_TIPO_gdf, SHP_DENUE_2020_gdf, 'UE_20', 'Emp_20')\n",
    "calcular_datos(MAPA_TIPO_gdf, SHP_DENUE_2010_gdf, 'UE_10', 'Emp_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a5b145f-491d-469d-8bdb-747dc249dd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#Tamaño de unidades promedio: Empleados entre UE por manzana\n",
    "MAPA_TIPO_gdf['TAMAÑO'] = MAPA_TIPO_gdf['Emp_20'] / MAPA_TIPO_gdf['UE_20']\n",
    "\n",
    "# Calcular las sumas de POPTOT2020 y POPTOT2010 por CVE_MET\n",
    "sum_emptot2020 = MAPA_TIPO_gdf.groupby('CVEMUN')['Emp_20'].transform('sum')\n",
    "sum_emptot2010 = MAPA_TIPO_gdf.groupby('CVEMUN')['Emp_10'].transform('sum')\n",
    "\n",
    "# Calcular TASA_POP_MUN\n",
    "MAPA_TIPO_gdf['TASA_EMP_MUN'] = (((sum_emptot2020 / sum_emptot2010) ** (1/10)) - 1) * 100\n",
    "print(8)\n",
    "#resto de campos\n",
    "MAPA_TIPO_gdf['DIF_EMP'] = MAPA_TIPO_gdf['Emp_20'] - MAPA_TIPO_gdf['Emp_10']\n",
    "MAPA_TIPO_gdf['DIF_UEC'] = MAPA_TIPO_gdf['UE_20'] - MAPA_TIPO_gdf['UE_10']\n",
    "MAPA_TIPO_gdf['REL_EMP'] = MAPA_TIPO_gdf['DIF_EMP'] / MAPA_TIPO_gdf['Emp_10']\n",
    "MAPA_TIPO_gdf['REL_UEC'] = MAPA_TIPO_gdf['DIF_UEC'] / MAPA_TIPO_gdf['UE_10']\n",
    "MAPA_TIPO_gdf['CVE_EMP'] = np.where(MAPA_TIPO_gdf['REL_EMP'] < -0.000000001, '1', '2')\n",
    "MAPA_TIPO_gdf['CVE_UEC'] = np.where(MAPA_TIPO_gdf['REL_UEC'] < -.1, 'A',\n",
    "                                   np.where((MAPA_TIPO_gdf['REL_UEC'] >= -.1) & (MAPA_TIPO_gdf['REL_UEC'] <= .1), \n",
    "                                            'B', 'C'))\n",
    "MAPA_TIPO_gdf['CVE_ue'] = MAPA_TIPO_gdf['CVE_UEC'].astype(str) + MAPA_TIPO_gdf['CVE_EMP']\n",
    "conditions = [\n",
    "    (MAPA_TIPO_gdf['Emp_20'] == 0),\n",
    "    (MAPA_TIPO_gdf['Emp_10'] == 0) & (MAPA_TIPO_gdf['UE_10'] == 0) & (MAPA_TIPO_gdf['CVE_ue'] == 'C2')\n",
    "]\n",
    "choices = ['00', 'C2+']\n",
    "MAPA_TIPO_gdf['TIPOLOGIA_ue'] = np.select(conditions, choices, default=MAPA_TIPO_gdf['CVE_ue'])\n",
    "\n",
    "MAPA_TIPO_gdf['DENS_EMP20'] = MAPA_TIPO_gdf['Emp_20'] / MAPA_TIPO_gdf['area_ha']\n",
    "MAPA_TIPO_gdf['DENS_EMP10'] = MAPA_TIPO_gdf['Emp_10'] / MAPA_TIPO_gdf['area_2010']\n",
    "\n",
    "MAPA_TIPO_gdf['DENS_UEC20'] = MAPA_TIPO_gdf['UE_20'] / MAPA_TIPO_gdf['area_ha']\n",
    "MAPA_TIPO_gdf['DENS_UEC10'] = MAPA_TIPO_gdf['UE_10'] / MAPA_TIPO_gdf['area_2010']\n",
    "\n",
    "\n",
    "def asignar_subtipologia(row):\n",
    "    # Valores específicos para deshabitación\n",
    "    rangos_deshabitacion_grupo = [0, 1, 30, 100]  # Modifica estos valores según tus necesidades\n",
    "    \n",
    "# Asignar subtipología según los rangos definidos\n",
    "    if rangos_deshabitacion_grupo[0] <= row['TAMAÑO'] < rangos_deshabitacion_grupo[1]:\n",
    "        return 'SUE'\n",
    "    elif rangos_deshabitacion_grupo[1] <= row['TAMAÑO'] < rangos_deshabitacion_grupo[2]:\n",
    "        return 'MICRO'\n",
    "    elif rangos_deshabitacion_grupo[2] <= row['TAMAÑO'] < rangos_deshabitacion_grupo[3]:\n",
    "        return 'MEDIANA'\n",
    "    elif row['TAMAÑO'] >= rangos_deshabitacion_grupo[3]:\n",
    "        return 'GRANDE'\n",
    "    else:\n",
    "        return '0'  # Valor predeterminado\n",
    "print(11)\n",
    "\n",
    "# Crear un nuevo campo 'R_DESHAB' y llenarlo con las subtipologías asignadas\n",
    "MAPA_TIPO_gdf['R_TAM'] = MAPA_TIPO_gdf.apply(asignar_subtipologia, axis=1)\n",
    "\n",
    "# Crear el campo SUBTIPOLOGÍA\n",
    "MAPA_TIPO_gdf['SUBTIPOLOGÍA_ue'] = MAPA_TIPO_gdf['TIPOLOGIA_ue'].astype(str) + '-' + MAPA_TIPO_gdf['R_TAM'].astype(str)\n",
    "print(12)\n",
    "\n",
    "# Guardar el GeoPackage con los nuevos campos\n",
    "MAPA_TIPO_gdf.to_file(MAPA_TIPO_ruta, layer='Loc_SubTipologias_ue', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857f1487-9455-40d5-bed8-4b9a56e68ea1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# No recuerdo esta sección y si era reelevante para esta parte del análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d32633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# Rutas de los archivos\n",
    "ruta_bruto = r\"C:\\Users\\ADMIN\\Desktop\\Ejercicio\\Localidad\\estadísticas_bruto_metrópoli.xlsx\"\n",
    "ruta_neto = r\"C:\\Users\\ADMIN\\OneDrive - Universidad de Guadalajara\\3. Voces\\2024\\Tipologías\\Nacional\\estadísticas_por_metropoli.xlsx\"\n",
    "ruta_salida = r\"C:\\Users\\ADMIN\\Desktop\\Ejercicio\\Localidad\\estadísticas_unidas_metrópoli.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cea4d-6250-418d-b009-a2d16134d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "\n",
    "# Filtrar polígonos por categoría 'Urbana' y 'Rural' con CALIF_CLAS diferente de '0'\n",
    "MAPA_TIPO_urbana = MAPA_TIPO_gdf[MAPA_TIPO_gdf['AMBITO'] == 'Urbana']\n",
    "MAPA_TIPO_rural = MAPA_TIPO_gdf[(MAPA_TIPO_gdf['AMBITO'] == 'Rural') & (MAPA_TIPO_gdf['CALIF_CLAS'] != '0')]\n",
    "\n",
    "# Concatenar los GeoDataFrames filtrados\n",
    "MAPA_TIPO_filtrado = pd.concat([MAPA_TIPO_urbana, MAPA_TIPO_rural])\n",
    "\n",
    "# Columnas que se sumarán\n",
    "columnas_a_sumar = ['POPTOT2010', 'POPTOT2020', 'VIVTOT2010', 'VIVTOT2020', \n",
    "    'TVIVHAB2010', 'TVIVHAB2020', 'TVIVPAR2010', 'TVIVPAR2020',\n",
    "    'TVIVPARHAB2010', 'TVIVPARHAB2020', 'VIVPAR_HAB2010', 'VIVPAR_HAB2020',\n",
    "    'VIVPAR_UT2010', 'VIVPAR_UT2020', 'OCUPVIVPAR2010', 'OCUPVIVPAR2020',\n",
    "    'VIVPAR_DES2010', 'VIVPAR_DES2020', 'VIV1C2010', 'VIV1C2020', \n",
    "    'VIV2C2010', 'VIV2C2020', 'VIV3C2010', 'VIV3C2020', 'area_ha',\n",
    "    'UE_20', 'Emp_20', 'UE_10', 'Emp_10']\n",
    "\n",
    "# Sumar las columnas y agrupar por 'NOM_MET'\n",
    "MAPA_TIPO_sumado = MAPA_TIPO_filtrado.groupby(['CVE_MET','CVEMUN','NOM_MET', 'TIPO_MET','TIPO_MUN'])[columnas_a_sumar].sum(numeric_only=True).reset_index()\n",
    "\n",
    "# Contar las manzanas agrupadas\n",
    "MAPA_TIPO_sumado['Localidades'] = MAPA_TIPO_filtrado.groupby(['CVEMUN', 'NOM_MET', 'TIPO_MET','TIPO_MUN']).size().values\n",
    "\n",
    "\n",
    "\n",
    "# # Intentar cargar el archivo CSV con diferentes codificaciones y asegurar que las columnas sean string\n",
    "# try:\n",
    "#     agem_df = pd.read_csv(\"C:/Users/ADMIN/Downloads/AGEM.csv\", usecols=['CVEMUN', 'NOM_MUN'], dtype=str, encoding='latin1')\n",
    "# except UnicodeDecodeError:\n",
    "#     agem_df = pd.read_csv(\"C:/Users/ADMIN/Downloads/AGEM.csv\", usecols=['CVEMUN', 'NOM_MUN'], dtype=str, encoding='iso-8859-1')\n",
    "\n",
    "# # Hacer el join con el archivo CSV basado en 'CVEMUN'\n",
    "# MAPA_TIPO_sumado = pd.merge(MAPA_TIPO_sumado, agem_df, on='CVEMUN', how='left')\n",
    "\n",
    "\n",
    "# Recalcular los campos\n",
    "MAPA_TIPO_sumado['DIFPOP'] = MAPA_TIPO_sumado['POPTOT2020'] - MAPA_TIPO_sumado['POPTOT2010']\n",
    "MAPA_TIPO_sumado['DIFVIV'] = MAPA_TIPO_sumado['VIVTOT2020'] - MAPA_TIPO_sumado['VIVTOT2010']\n",
    "MAPA_TIPO_sumado['RELPOP'] = MAPA_TIPO_sumado['DIFPOP'] / MAPA_TIPO_sumado['POPTOT2010']\n",
    "MAPA_TIPO_sumado['RELVIV'] = MAPA_TIPO_sumado['DIFVIV'] / MAPA_TIPO_sumado['VIVTOT2010']\n",
    "MAPA_TIPO_sumado['CVEPOP'] = np.where(MAPA_TIPO_sumado['RELPOP'] < -0.000000001, 'A', 'B')\n",
    "MAPA_TIPO_sumado['CVEVIV'] = np.where(MAPA_TIPO_sumado['RELVIV'] < -.0703, '1',\n",
    "                                      np.where((MAPA_TIPO_sumado['RELVIV'] >= -.0703) & (MAPA_TIPO_sumado['RELVIV'] <= .0703), \n",
    "                                               '2', '3'))\n",
    "MAPA_TIPO_sumado['CVE'] = MAPA_TIPO_sumado['CVEPOP'] + MAPA_TIPO_sumado['CVEVIV'].astype(str)\n",
    "\n",
    "conditions = [\n",
    "    (MAPA_TIPO_sumado['POPTOT2020'] == 0),\n",
    "    (MAPA_TIPO_sumado['POPTOT2010'] == 0) & (MAPA_TIPO_sumado['VIVTOT2010'] == 0) & (MAPA_TIPO_sumado['CVE'] == 'B3')\n",
    "]\n",
    "choices = ['DH', 'B3\\'']\n",
    "MAPA_TIPO_sumado['TIPOLOGIA'] = np.select(conditions, choices, default=MAPA_TIPO_sumado['CVE'])\n",
    "\n",
    "MAPA_TIPO_sumado['DENS_POP10'] = MAPA_TIPO_sumado['POPTOT2010'] / MAPA_TIPO_sumado['area_ha']\n",
    "MAPA_TIPO_sumado['DENS_POP20'] = MAPA_TIPO_sumado['POPTOT2020'] / MAPA_TIPO_sumado['area_ha']\n",
    "MAPA_TIPO_sumado['DIF_DENSPOP'] = MAPA_TIPO_sumado['DENS_POP20'] - MAPA_TIPO_sumado['DENS_POP10']\n",
    "\n",
    "MAPA_TIPO_sumado['DENS_VIV10'] = MAPA_TIPO_sumado['VIVTOT2010'] / MAPA_TIPO_sumado['area_ha']\n",
    "MAPA_TIPO_sumado['DENS_VIV20'] = MAPA_TIPO_sumado['VIVTOT2020'] / MAPA_TIPO_sumado['area_ha']\n",
    "MAPA_TIPO_sumado['DIF_DENSVIV'] = MAPA_TIPO_sumado['DENS_VIV20'] - MAPA_TIPO_sumado['DENS_VIV10']\n",
    "\n",
    "MAPA_TIPO_sumado['CUARTOS2010'] = ((MAPA_TIPO_sumado['VIV1C2010'] * 1) + (MAPA_TIPO_sumado['VIV2C2010'] * 2) + (MAPA_TIPO_sumado['VIV3C2010'] * 4))\n",
    "MAPA_TIPO_sumado['CUARTOS2020'] = ((MAPA_TIPO_sumado['VIV1C2020'] * 1) + (MAPA_TIPO_sumado['VIV2C2020'] * 2) + (MAPA_TIPO_sumado['VIV3C2020'] * 4))\n",
    "\n",
    "MAPA_TIPO_sumado['CPERC2010'] = MAPA_TIPO_sumado['CUARTOS2010'] / MAPA_TIPO_sumado['POPTOT2010']\n",
    "MAPA_TIPO_sumado['CPERC2020'] = MAPA_TIPO_sumado['CUARTOS2020'] / MAPA_TIPO_sumado['POPTOT2020']\n",
    "MAPA_TIPO_sumado['DIF_CPERC'] = MAPA_TIPO_sumado['CPERC2020'] - MAPA_TIPO_sumado['CPERC2010']\n",
    "\n",
    "MAPA_TIPO_sumado['HABXVIV2010'] = MAPA_TIPO_sumado['POPTOT2010'] / MAPA_TIPO_sumado['VIVTOT2010']\n",
    "MAPA_TIPO_sumado['HABXVIV2020'] = MAPA_TIPO_sumado['POPTOT2020'] / MAPA_TIPO_sumado['VIVTOT2020']\n",
    "MAPA_TIPO_sumado['DIF_HABXVIV'] = MAPA_TIPO_sumado['HABXVIV2020'] - MAPA_TIPO_sumado['HABXVIV2010']\n",
    "\n",
    "\n",
    "MAPA_TIPO_sumado['DESHABITACION_2010'] = MAPA_TIPO_sumado['VIVPAR_DES2010'] / MAPA_TIPO_sumado['VIVTOT2010']\n",
    "MAPA_TIPO_sumado['DESHABITACION_2020'] = MAPA_TIPO_sumado['VIVPAR_DES2020'] / MAPA_TIPO_sumado['VIVTOT2020']\n",
    "MAPA_TIPO_sumado['DIF_DESHAB'] = MAPA_TIPO_sumado['DESHABITACION_2020'] - MAPA_TIPO_sumado['DESHABITACION_2010']\n",
    "\n",
    "# Calcular TASA_POP_MUN\n",
    "MAPA_TIPO_sumado['TASA_POP'] = (((MAPA_TIPO_sumado['POPTOT2020'] / MAPA_TIPO_sumado['POPTOT2010']) ** (1/10)) - 1) * 100\n",
    "MAPA_TIPO_sumado['TASA_VIV'] = (((MAPA_TIPO_sumado['VIVTOT2020'] / MAPA_TIPO_sumado['VIVTOT2010']) ** (1/10)) - 1) * 100\n",
    "\n",
    "def asignar_subtipologia_2010(row):\n",
    "    # Valores específicos para deshabitación\n",
    "    rangos_deshabitacion_grupo = [0, .0703, .1416, .2812]  # Modifica estos valores según tus necesidades\n",
    "    \n",
    "    # Asignar subtipología según los rangos definidos\n",
    "    if rangos_deshabitacion_grupo[0] <= row['DESHABITACION_2010'] < rangos_deshabitacion_grupo[1]:\n",
    "        return 'a'\n",
    "    elif rangos_deshabitacion_grupo[1] <= row['DESHABITACION_2010'] < rangos_deshabitacion_grupo[2]:\n",
    "        return 'b'\n",
    "    elif rangos_deshabitacion_grupo[2] <= row['DESHABITACION_2010'] < rangos_deshabitacion_grupo[3]:\n",
    "        return 'c'\n",
    "    elif row['DESHABITACION_2010'] >= rangos_deshabitacion_grupo[3]:\n",
    "        return 'd'\n",
    "    else:\n",
    "        return '0'  # Valor predeterminado\n",
    "\n",
    "    \n",
    "def asignar_subtipologia_2020(row):\n",
    "    # Valores específicos para deshabitación\n",
    "    rangos_deshabitacion_grupo = [0, .0703, .1416, .2812]  # Modifica estos valores según tus necesidades\n",
    "    \n",
    "    # Asignar subtipología según los rangos definidos\n",
    "    if rangos_deshabitacion_grupo[0] <= row['DESHABITACION_2020'] < rangos_deshabitacion_grupo[1]:\n",
    "        return 'a'\n",
    "    elif rangos_deshabitacion_grupo[1] <= row['DESHABITACION_2020'] < rangos_deshabitacion_grupo[2]:\n",
    "        return 'b'\n",
    "    elif rangos_deshabitacion_grupo[2] <= row['DESHABITACION_2020'] < rangos_deshabitacion_grupo[3]:\n",
    "        return 'c'\n",
    "    elif row['DESHABITACION_2020'] >= rangos_deshabitacion_grupo[3]:\n",
    "        return 'd'\n",
    "    else:\n",
    "        return '0'  # Valor predeterminado\n",
    "\n",
    "\n",
    "# Crear un nuevo campo 'R_DESHAB' y llenarlo con las subtipologías asignadas\n",
    "MAPA_TIPO_sumado['R_DESHAB_2010'] = MAPA_TIPO_sumado.apply(asignar_subtipologia_2010, axis=1)\n",
    "\n",
    "# Crear un nuevo campo 'R_DESHAB' y llenarlo con las subtipologías asignadas\n",
    "MAPA_TIPO_sumado['R_DESHAB_2020'] = MAPA_TIPO_sumado.apply(asignar_subtipologia_2020, axis=1)\n",
    "\n",
    "# Crear el campo SUBTIPOLOGÍA\n",
    "MAPA_TIPO_sumado['SUBTIPOLOGÍA'] = MAPA_TIPO_sumado['TIPOLOGIA'].astype(str) + '-' + MAPA_TIPO_sumado['R_DESHAB_2020'].astype(str)\n",
    "\n",
    "############################################indicadores DENUE\n",
    "\n",
    "#Tamaño de unidades promedio: Empleados entre UE por manzana\n",
    "MAPA_TIPO_sumado['TAMAÑO'] = MAPA_TIPO_sumado['Emp_20'] / MAPA_TIPO_sumado['UE_20']\n",
    "\n",
    "# Calcular las sumas de POPTOT2020 y POPTOT2010 por CVE_MET\n",
    "sum_emptot2020 = MAPA_TIPO_sumado.groupby('CVEMUN')['Emp_20'].transform('sum')\n",
    "sum_emptot2010 = MAPA_TIPO_sumado.groupby('CVEMUN')['Emp_10'].transform('sum')\n",
    "\n",
    "# Calcular TASA_POP_MUN\n",
    "MAPA_TIPO_sumado['TASA_EMP_MUN'] = (((sum_emptot2020 / sum_emptot2010) ** (1/10)) - 1) * 100\n",
    "\n",
    "#resto de campos\n",
    "MAPA_TIPO_sumado['DIF_EMP'] = MAPA_TIPO_sumado['Emp_20'] - MAPA_TIPO_sumado['Emp_10']\n",
    "MAPA_TIPO_sumado['DIF_UEC'] = MAPA_TIPO_sumado['UE_20'] - MAPA_TIPO_sumado['UE_10']\n",
    "MAPA_TIPO_sumado['REL_EMP'] = MAPA_TIPO_sumado['DIF_EMP'] / MAPA_TIPO_sumado['Emp_10']\n",
    "MAPA_TIPO_sumado['REL_UEC'] = MAPA_TIPO_sumado['DIF_UEC'] / MAPA_TIPO_sumado['UE_10']\n",
    "MAPA_TIPO_sumado['CVE_EMP'] = np.where(MAPA_TIPO_sumado['REL_EMP'] < -0.000000001, '1', '2')\n",
    "MAPA_TIPO_sumado['CVE_UEC'] = np.where(MAPA_TIPO_sumado['REL_UEC'] < -.1, 'A',\n",
    "                                   np.where((MAPA_TIPO_sumado['REL_UEC'] >= -.1) & (MAPA_TIPO_sumado['REL_UEC'] <= .1), \n",
    "                                            'B', 'C'))\n",
    "MAPA_TIPO_sumado['CVE_ue'] = MAPA_TIPO_sumado['CVE_UEC'].astype(str) + MAPA_TIPO_sumado['CVE_EMP']\n",
    "conditions = [\n",
    "    (MAPA_TIPO_sumado['Emp_20'] == 0),\n",
    "    (MAPA_TIPO_sumado['Emp_10'] == 0) & (MAPA_TIPO_sumado['UE_10'] == 0) & (MAPA_TIPO_sumado['CVE_ue'] == 'C2')\n",
    "]\n",
    "choices = ['00', 'C2+']\n",
    "MAPA_TIPO_sumado['TIPOLOGIA_ue'] = np.select(conditions, choices, default=MAPA_TIPO_sumado['CVE_ue'])\n",
    "\n",
    "MAPA_TIPO_sumado['DENS_EMP20'] = MAPA_TIPO_sumado['Emp_20'] / MAPA_TIPO_sumado['area_ha']\n",
    "MAPA_TIPO_sumado['DENS_EMP10'] = MAPA_TIPO_sumado['Emp_10'] / MAPA_TIPO_sumado['area_ha']\n",
    "\n",
    "MAPA_TIPO_sumado['DENS_UEC20'] = MAPA_TIPO_sumado['UE_20'] / MAPA_TIPO_sumado['area_ha']\n",
    "MAPA_TIPO_sumado['DENS_UEC10'] = MAPA_TIPO_sumado['UE_10'] / MAPA_TIPO_sumado['area_ha']\n",
    "\n",
    "\n",
    "def asignar_subtipologia(row):\n",
    "    # Valores específicos para deshabitación\n",
    "    rangos_deshabitacion_grupo = [0, 1, 30, 100]  # Modifica estos valores según tus necesidades\n",
    "    \n",
    "# Asignar subtipología según los rangos definidos\n",
    "    if rangos_deshabitacion_grupo[0] <= row['TAMAÑO'] < rangos_deshabitacion_grupo[1]:\n",
    "        return 'SUE'\n",
    "    elif rangos_deshabitacion_grupo[1] <= row['TAMAÑO'] < rangos_deshabitacion_grupo[2]:\n",
    "        return 'MICRO'\n",
    "    elif rangos_deshabitacion_grupo[2] <= row['TAMAÑO'] < rangos_deshabitacion_grupo[3]:\n",
    "        return 'MEDIANA'\n",
    "    elif row['TAMAÑO'] >= rangos_deshabitacion_grupo[3]:\n",
    "        return 'GRANDE'\n",
    "    else:\n",
    "        return '0'  # Valor predeterminado\n",
    "\n",
    "# Crear un nuevo campo 'R_DESHAB' y llenarlo con las subtipologías asignadas\n",
    "MAPA_TIPO_sumado['R_TAM'] = MAPA_TIPO_sumado.apply(asignar_subtipologia, axis=1)\n",
    "\n",
    "# Crear el campo SUBTIPOLOGÍA\n",
    "MAPA_TIPO_sumado['SUBTIPOLOGÍA_ue'] = MAPA_TIPO_sumado['TIPOLOGIA_ue'].astype(str) + '-' + MAPA_TIPO_sumado['R_TAM'].astype(str)\n",
    "\n",
    "###################################################################\n",
    "\n",
    "# Redondear a 3 decimales\n",
    "MAPA_TIPO_sumado = MAPA_TIPO_sumado.round(3)\n",
    "\n",
    "# Reordenar columnas: 'NOM_MUN', 'NOM_MET', 'TIPO_MET' al inicio y 'TIPO_MUN' al final\n",
    "column_order = ['CVEMUN', 'NOM_MET', 'TIPO_MET'] + [col for col in MAPA_TIPO_sumado.columns if col not in ['CVEMUN', 'NOM_MET', 'TIPO_MET', 'TIPO_MUN']] + ['TIPO_MUN']\n",
    "MAPA_TIPO_sumado = MAPA_TIPO_sumado[column_order]\n",
    "\n",
    "# Guardar los datos en un archivo Excel\n",
    "# excel_path = 'C:/Users/ADMIN/Desktop/Ejercicio/Localidad/resultados_municipio.xlsx'\n",
    "excel_path = r\"C:\\Users\\Alejandro\\Downloads\\DATA\\Tratados\\NAC\\DENUE_LOC_NAC\\resultados_municipio.xlsx\"\n",
    "MAPA_TIPO_sumado.to_excel(excel_path, index=False)\n",
    "\n",
    "# Leer el archivo Excel\n",
    "wb = openpyxl.load_workbook(excel_path)\n",
    "\n",
    "# Seleccionar la hoja de cálculo\n",
    "sheet = wb.active\n",
    "\n",
    "# Ajustar el ancho de las columnas automáticamente\n",
    "for col in sheet.columns:\n",
    "    max_length = 0\n",
    "    column = col[0].column_letter\n",
    "    for cell in col:\n",
    "        try:\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(cell.value)\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = (max_length + 2) * 1.2\n",
    "    sheet.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# Aplicar color rojo a las celdas negativas en columnas con prefijo 'DIF_'\n",
    "red_font = Font(color=\"FF0000\")\n",
    "\n",
    "for col in sheet.iter_cols(min_row=2, min_col=1, max_col=sheet.max_column):\n",
    "    col_name = sheet.cell(row=1, column=col[0].column).value\n",
    "    if col_name.startswith('DIF_'):\n",
    "        for cell in col:\n",
    "            if isinstance(cell.value, (int, float)) and cell.value < 0:\n",
    "                cell.font = red_font\n",
    "\n",
    "# Guardar los cambios en el archivo Excel\n",
    "# wb.save('C:/Users/ADMIN/Desktop/Ejercicio/Localidad/estadísticas_bruto_municipio.xlsx')\n",
    "wb.save(r\"C:\\Users\\Alejandro\\Downloads\\DATA\\Tratados\\NAC\\DENUE_LOC_NAC\\estadísticas_bruto_municipio.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26c109fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los archivos Excel\n",
    "df_bruto = pd.read_excel(ruta_bruto)\n",
    "df_neto = pd.read_excel(ruta_neto)\n",
    "\n",
    "# Añadir prefijos a las columnas\n",
    "df_bruto = df_bruto.add_prefix('bruto_')\n",
    "df_neto = df_neto.add_prefix('neto_')\n",
    "\n",
    "# Cambiar el nombre de la columna 'bruto_NOM_MET' a 'NOM_MET' para realizar el merge\n",
    "df_bruto = df_bruto.rename(columns={'bruto_NOM_MET': 'NOM_MET'})\n",
    "df_neto = df_neto.rename(columns={'neto_NOM_MET': 'NOM_MET'})\n",
    "\n",
    "# Realizar la unión por 'NOM_MET'\n",
    "df_merged = pd.merge(df_bruto, df_neto, on='NOM_MET', how='outer')\n",
    "\n",
    "# Reordenar las columnas\n",
    "cols = sorted(df_merged.columns, key=lambda x: (x.split('_')[-1], x))\n",
    "df_merged = df_merged[['NOM_MET'] + [col for col in cols if col != 'NOM_MET']]\n",
    "\n",
    "# Guardar el DataFrame resultante a un nuevo archivo Excel\n",
    "df_merged.to_excel(ruta_salida, index=False)\n",
    "\n",
    "# Ajustar el tamaño de las columnas y aplicar estilos\n",
    "wb = openpyxl.load_workbook(ruta_salida)\n",
    "ws = wb.active\n",
    "\n",
    "# Ajustar el tamaño de las columnas basado en el nombre del campo\n",
    "for col in ws.columns:\n",
    "    max_length = 0\n",
    "    column = col[0].column_letter # Get the column name\n",
    "    for cell in col:\n",
    "        try:\n",
    "            if len(str(cell.value)) > max_length:\n",
    "                max_length = len(cell.value)\n",
    "        except:\n",
    "            pass\n",
    "    adjusted_width = (max_length + 2)\n",
    "    ws.column_dimensions[column].width = adjusted_width\n",
    "\n",
    "# Cambiar la fuente a Roboto y colorear valores menores a 0\n",
    "roboto_font = Font(name='Roboto')\n",
    "\n",
    "for row in ws.iter_rows(min_row=2):\n",
    "    for cell in row:\n",
    "        cell.font = roboto_font\n",
    "        if cell.value is not None and isinstance(cell.value, (int, float)) and cell.value < 0:\n",
    "            cell.font = Font(color=\"FF0000\", name='Roboto')\n",
    "\n",
    "# Guardar los cambios en el archivo Excel\n",
    "wb.save(ruta_salida)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
